---

## Experiment settings for Federated Learning with NeRF on Colosseum_1 dataset
expname: "colosseum_1_test"
basedir: "./logs"
datadir: "./data/nerf_llff_data/colosseum_1_processed"
dataset_type: "llff"

# N_rand: 1024

## training options
config: true          # config file path
netdepth: 8           # layers in network
netwidth: 256         # channels per layer
netdepth_fine: 8      # layers in fine network
netwidth_fine: 256    # channels per layer in fine network
N_rand: 4096          # 32*32*4 batch size (number of random rays per gradient step)
lrate: 5e-4           # 0.0005 learning rate
lrate_decay: 250      # exponential learning rate decay (in 1000 steps)
chunk: 32768          # 1024*32 number of rays processed in parallel, decrease if running out of memory
netchunk: 65536       # 1024*64 number of pts sent through network in parallel, decrease if running out of memory')
no_batching: false    # action='store_true', help='only take random rays from 1 image at a time')
no_reload: false      # action='store_true', help='do not reload weights from saved ckpt')
ft_path: null         # default=None, help='specific weights npy file to reload for coarse network')

# rendering options
N_samples: 64         # number of coarse samples per ray
N_importance: 64      # number of additional fine samples per ray 
perturb: 1.0           # set to 0. for no jitter, 1. for jitter
use_viewdirs: true    # action='store_true', help='use full 5D input instead of 3D
i_embed: 0            # set 0 for default positional encoding, -1 for none
multires: 10          # log2 of max freq for positional encoding (3D location)
multires_views: 4     # log2 of max freq for positional encoding (2D direction)
raw_noise_std: 1e0    # std dev of noise added to regularize sigma_a output, 1e0 recommended
render_only: false    # action='store_true' help='do not optimize, reload weights and render out render_poses path
render_test: false    # action='store_true', help='render the test set instead of render_poses path
render_factor: 0      # downsampling factor to speed up rendering, set 4 or 8 for fast preview

## training options
precrop_iters: 0      # number of steps to train on central crops
precrop_frac: 0.5      # fraction of img taken for central crops') 

## dataset options
testskip: 8           # will load 1/N images from test/val sets, useful for large datasets like deepvoxels

## deepvoxels flags
shape: "greek"        # options: armchair / cube / greek / vase (deepvoxels)

## blender flags
white_bkgd: false     # action='store_true', help=set to render synthetic data on a white bkgd (always use for dvoxels)
half_res: false       # action='store_true', help=load blender synthetic data at 400x400 instead of 800x800

## llff flags
factor: 8             # downsample factor for LLFF images
no_ndc: false         # action='store_true', help= do not use normalized device coordinates (set for non-forward facing scenes)
lindisp: false        # action='store_true', help= sampling linearly in disparity rather than depth
spherify: True        # action='store_true', help= set for spherical 360 scenes
llffhold: 8           # type=int, default=8, help= will take every 1/N images as LLFF test set, paper uses 8

## logging/saving options
i_print: 100          # help='frequency of console printout and metric loggin')
i_img: 500            # help='frequency of tensorboard image logging')
i_weights: 10000      # help='frequency of weight ckpt saving')
i_testset: 50000      # help='frequency of testset saving')
i_video: 50000        # help='frequency of render_poses video saving')